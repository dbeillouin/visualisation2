}
}
data.gen <- function(dat, mle) {
# Generate effect sizes based on the estimated mu and tau²
data.frame(yi = rnorm(nrow(dat), mle$mu, sqrt(mle$tau2 + dat$vi)), vi = dat$vi)
}
res.boot <- boot(dat, boot.func, R=10000, sim="parametric", ran.gen=data.gen, mle=list(mu=coef(res), tau2=res$tau2))
```{r}
set.seed(1234)  # For reproducibility
library(boot)
# Confidence intervals for mu
boot.ci(res.boot, type=c("norm", "basic", "stud", "perc"), index=1:2)
res.boot <- boot(dat, boot.func, R=100, sim="parametric", ran.gen=data.gen, mle=list(mu=coef(res), tau2=res$tau2))
boot.ci(res.boot, type=c("norm", "basic", "stud", "perc"), index=1:2)
# Confidence intervals for tau²
boot.ci(res.boot, type=c("norm", "basic", "stud", "perc"), index=3:4)
boot.func <- function(dat, indices) {
# Resample the data based on the given indices
sel <- dat[indices,]
# Fit the random-effects model to the resampled data
res <- try(suppressWarnings(rma(yi, vi, data=sel)), silent=TRUE)
# Return NA if the model did not converge
if (inherits(res, "try-error")) {
return(NA)
} else {
return(c(coef(res), vcov(res), res$tau2, res$se.tau2^2))
}
}
set.seed(1234)  # For reproducibility
res.boot <- boot(dat, boot.func, R=10000)
set.seed(1234)  # For reproducibility
res.boot <- boot(dat, boot.func, R=100)
# Confidence intervals for mu
boot.ci(res.boot, index=1:2)
# Confidence intervals for tau²
boot.ci(res.boot, index=3:4)
plot(density(res.boot$t[,1]), main="Bootstrap Distribution of Mu")
abline(v=quantile(res.boot$t[,1], probs=c(0.025, 0.975)), col="red")
boot.func <- function(dat, indices) {
# Resample the data based on the given indices
sel <- dat[indices,]
# Try to fit the random-effects model to the resampled data
res <- tryCatch({
suppressWarnings(rma(yi, vi, data=sel))
}, error = function(e) NA)
# Return NA if the model did not converge or if fitting failed
if (is.na(res) || inherits(res, "try-error")) {
return(rep(NA, 4))  # Return a vector of NAs if the model fails
} else {
# Return the desired statistics if model fitting was successful
return(c(coef(res), vcov(res), res$tau2, res$se.tau2^2))
}
}
res.boot <- boot(dat, boot.func, R=100)
boot.func <- function(dat, indices) {
# Resample the data based on the given indices
sel <- dat[indices,]
# Fit the random-effects model to the resampled data
res <- try(suppressWarnings(rma(yi, vi, data=sel)), silent=TRUE)
# Return NA if the model did not converge
if (inherits(res, "try-error")) {
return(NA)
} else {
return(c(coef(res), vcov(res), res$tau2, res$se.tau2^2))
}
}
res.boot <- boot(dat, boot.func, R=100)
res.boot
boot.ci(res.boot, index=1:2)
# Confidence intervals for tau²
boot.ci(res.boot, index=3:4)
plot(density(res.boot$t[,1]), main="Bootstrap Distribution of Mu")
abline(v=quantile(res.boot$t[,1], probs=c(0.025, 0.975)), col="red")
dat
boot.func <- function(data.boot) {
# Fit the random-effects model to the bootstrap data
res <- try(suppressWarnings(rma(yi, vi, data=data.boot)), silent=TRUE)
# Return NA if the model did not converge
if (inherits(res, "try-error")) {
return(NA)
} else {
# Extract the estimated effect size (mu), its variance, tau², and its variance
return(c(coef(res), vcov(res), res$tau2, res$se.tau2^2))
}
}
data.gen <- function(dat, mle) {
# Generate effect sizes based on the estimated mu and tau²
data.frame(yi = rnorm(nrow(dat), mle$mu, sqrt(mle$tau2 + dat$vi)), vi = dat$vi)
boot.func <- function(data.boot) {
# Fit the random-effects model to the bootstrap data
res <- try(suppressWarnings(rma(yi, vi, data=data.boot)), silent=TRUE)
# Return NA if the model did not converge
if (inherits(res, "try-error")) {
return(NA)
} else {
# Extract the estimated effect size (mu), its variance, tau², and its variance
return(c(coef(res), vcov(res), res$tau2, res$se.tau2^2))
}
}
data.gen <- function(dat, mle) {
data.gen <- function(dat, mle) {
# Generate effect sizes based on the estimated mu and tau²
data.frame(yi = rnorm(nrow(dat), mle$mu, sqrt(mle$tau2 + dat$vi)), vi = dat$vi)
}
res.boot <- boot::boot(dat, boot.func, R=10000, sim="parametric", ran.gen=data.gen, mle=list(mu=coef(res), tau2=res$tau2))
res.boot <- boot::boot(dat, boot.func, R=100, sim="parametric", ran.gen=data.gen, mle=list(mu=coef(res), tau2=res$tau2))
2.7/100*98
---
title: "Calculate and combine the effect-sizes"
# Define the prior for both the intercept and the random effect
priors <- c(set_prior("normal(0, 1)", class = "b"),      # Prior for fixed effects (intercept)
set_prior("normal(0, 1)", class = "sd"))   # Prior for standard deviation of random effects
---
title: "Calculate and combine the effect-sizes"
library(brms)
# Define the prior for both the intercept and the random effect
priors <- c(set_prior("normal(0, 1)", class = "b"),      # Prior for fixed effects (intercept)
set_prior("normal(0, 1)", class = "sd"))   # Prior for standard deviation of random effects
# Fit the Bayesian random-effects model with specified priors
bayes_model <- brm(yi ~ 1 + (1 | study), data = dat,
prior = priors,
chains = 2, iter = 2000)
dat
# Fit the Bayesian random-effects model with specified priors
bayes_model <- brm(yi ~ 1 + (1 | paper), data = dat,
prior = priors,
chains = 2, iter = 2000)
library(brms)
# Define the response variable and the standard error
# Replace 'yi' with your actual response variable and 'se' with the appropriate standard error variable
response_var <- "yi"  # Change this to your response variable name
se_var <- "sqrt(vi)"  # Calculate the standard error (if vi is the variance)
# Fit the Bayesian random-effects model with specified priors
bayes_model <- brm(
formula = paste0(response_var, " | se(", se_var, ") ~ 1 + (1 | study)"),
data = dat,
family = gaussian,
prior = c(
prior(normal(0, 1), class = "Intercept"),   # Prior for the intercept
prior(cauchy(0, 1), class = "sd")            # Prior for the standard deviation of the random effect
),
iter = 2000,
warmup = 1000,
cores = 4,
chains = 4,
seed = 14
)
# Fit the Bayesian random-effects model with specified priors
bayes_model <- brm(
formula = paste0(response_var, " | se(", se_var, ") ~ 1 + (1 | paper)"),
data = dat,
family = gaussian,
prior = c(
prior(normal(0, 1), class = "Intercept"),   # Prior for the intercept
prior(cauchy(0, 1), class = "sd")            # Prior for the standard deviation of the random effect
),
iter = 2000,
warmup = 1000,
cores = 4,
chains = 4,
seed = 14
)
library(brms)
# Define the response variable and the standard error
# Replace 'yi' with your actual response variable and 'se' with the appropriate standard error variable
response_var <- "yi"  # Change this to your response variable name
se_var <- "sqrt(vi)"  # Calculate the standard error (if vi is the variance)
# Fit the Bayesian random-effects model with specified priors
bayes_model <- brm(
formula = paste0(response_var, " | se(", se_var, ") ~ 1 + (1 | paper)"),
data = dat,
family = gaussian,
prior = c(
prior(normal(0, 1), class = "Intercept"),   # Prior for the intercept
prior(cauchy(0, 1), class = "sd")            # Prior for the standard deviation of the random effect
),
iter = 200,
warmup = 100,
cores = 4,
chains = 4,
seed = 14
)
dat
# Fit the Bayesian random-effects model with specified priors
bayes_model <- brm(
formula = paste0(response_var, " | se(", se_var, ") ~ 1 + (1 | paper)"),
data = dat,
family = gaussian,
prior = c(
prior(normal(0, 1), class = "Intercept"),   # Prior for the intercept
prior(cauchy(0, 1), class = "sd")            # Prior for the standard deviation of the random effect
),
iter = 200,
warmup = 100,
cores = 4,
chains = 4,
seed = 14
)
dat<-cbind(dat, lnRR)
dat
# Install the RoBMA package (if not already installed)
install.packages("RoBMA")
# Load the RoBMA package
library(RoBMA)
install.packages("rjags")
# Load the RoBMA package
library(RoBMA)
library(rjags)
# Load the RoBMA package
library(RoBMA)
# Fit a robust Bayesian meta-analysis model
bayesian_model <- RoBMA(yi, vi)
# Fit a robust Bayesian meta-analysis model
bayesian_model <- RoBMA(yi, vi,data=dat)
# Fit a robust Bayesian meta-analysis model
bayesian_model <- RoBMA(dat$yi, dat$vi)
data <- data.frame(
study = c("Study1", "Study2", "Study3", "Study4", "Study5"),
smd = c(0.5, 0.8, 0.3, 1.0, 0.9),
var_smd = c(0.1, 0.15, 0.2, 0.05, 0.12)
)
# Fit a robust Bayesian meta-analysis model
bayesian_model <- RoBMA(data$smd, data$var_smd)
dat
head(dat)
# Load the necessary libraries
library(RoBMA)
# Ensure your dataset 'dat' is structured correctly
# Use the yi and vi columns from 'dat'
# Fit the Bayesian meta-analysis model
fit <- RoBMA(
d = dat$yi,                     # Effect sizes
se = sqrt(dat$vi),              # Standard errors from variances
study_names = dat$paper,        # Unique study identifiers
seed = 1                        # Seed for reproducibility
)
dat$paper
# Ensure your dataset 'dat' is structured correctly
# Use the yi and vi columns from 'dat'
# Fit the Bayesian meta-analysis model
fit <- RoBMA(
d = dat$yi,                     # Effect sizes
se = sqrt(dat$vi),              # Standard errors from variances
study_names = as.character(dat$paper),        # Unique study identifiers
seed = 1                        # Seed for reproducibility
)
fit <- RoBMA(d = Bem2011$d, se = Bem2011$se, study_names = Bem2011$study, seed = 1)
?RoBMA
fit <- RoBMA(d = Bem2011$d, se = Bem2011$se, study_names = Bem2011$study, seed = 1,
chains = 2,
sample = 500,
burnin = 200,)
fit <- RoBMA(d = Bem2011$d, se = Bem2011$se, study_names = Bem2011$study, seed = 1,
chains = 2,
sample = 500,
burnin = 200,parallel = TRUE)
fit <- RoBMA(
d = dat$yi,                     # Effect sizes
se = sqrt(dat$vi),              # Standard errors from variances
study_names = as.character(dat$paper),        # Unique study identifiers
seed = 1,                        # Seed for reproducibility
chains = 2,
sample = 500,
burnin = 200,parallel = TRUE)
# Summarize the results
summary(fit)
# Plot the results for the parameter of interest
plot(fit, parameter = "mu", xlim = c(-0.5, 0.5))  # Adjust xlim as necessary
plot(fit, type = "funnel", show_legend = TRUE)
# Plot the results for the parameter of interest
plot(fit, parameter = "mu", xlim = c(-0.5, 0.5))  # Adjust xlim as necessary
?fail.safe
# Calculate the Fail-Safe N
failsafe_n <- fsn(res)
failsafe_n
summary(res)
res$b
res$se
estimate <- res$b  # Replace with your meta-analytic estimate if needed
se <- res$se        # Replace with your standard error if needed
# Define a sequence for standard errors (SE) to create CI regions
se.seq <- seq(0, max(funnel_data$precision), 0.001)
# Define a sequence for standard errors (SE) to create CI regions
se.seq <- seq(0, max(data$var_smd), 0.001)
# Calculate 95% and 99% confidence intervals for the region
ll95 <- estimate - (1.96 * se.seq)
ul95 <- estimate + (1.96 * se.seq)
ll99 <- estimate - (3.29 * se.seq)
ul99 <- estimate + (3.29 * se.seq)
# Compute confidence intervals for the mean meta-analytic estimate
meanll95 <- estimate - (1.96 * se)
meanul95 <- estimate + (1.96 * se)
# Store all calculated values in a single data frame for easy plotting
dfCI <- data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)
# Draw the enhanced funnel plot with shaded CI regions and lines
funnel_plot <- funnel_plot +
# Add shaded areas for 95% and 99% CI regions
geom_ribbon(aes(x = se.seq, ymin = ll99, ymax = ul99), fill = "lightblue", alpha = 0.3) +
geom_ribbon(aes(x = se.seq, ymin = ll95, ymax = ul95), fill = "lightgreen", alpha = 0.5) +
# Draw dashed lines for 95% and 99% CI bounds
geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', color = 'blue', data = dfCI) +
geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', color = 'blue', data = dfCI) +
geom_line(aes(x = se.seq, y = ll99), linetype = 'dashed', color = 'darkgreen', data = dfCI) +
geom_line(aes(x = se.seq, y = ul99), linetype = 'dashed', color = 'darkgreen', data = dfCI) +
# Add horizontal lines for mean 95% CI bounds
geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype = 'dotted', color = 'red', data = dfCI) +
geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype = 'dotted', color = 'red', data = dfCI) +
# Customize axis scaling and layout for clarity
scale_x_reverse() +
coord_flip() +
theme_bw()
# Draw the enhanced funnel plot with shaded CI regions and lines
funnel_plot <- ggplot(aes(x = se, y = Zr), data = dat)+
# Add shaded areas for 95% and 99% CI regions
geom_ribbon(aes(x = se.seq, ymin = ll99, ymax = ul99), fill = "lightblue", alpha = 0.3) +
geom_ribbon(aes(x = se.seq, ymin = ll95, ymax = ul95), fill = "lightgreen", alpha = 0.5) +
# Draw dashed lines for 95% and 99% CI bounds
geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', color = 'blue', data = dfCI) +
geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', color = 'blue', data = dfCI) +
geom_line(aes(x = se.seq, y = ll99), linetype = 'dashed', color = 'darkgreen', data = dfCI) +
geom_line(aes(x = se.seq, y = ul99), linetype = 'dashed', color = 'darkgreen', data = dfCI) +
# Add horizontal lines for mean 95% CI bounds
geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype = 'dotted', color = 'red', data = dfCI) +
geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype = 'dotted', color = 'red', data = dfCI) +
# Customize axis scaling and layout for clarity
scale_x_reverse() +
coord_flip() +
theme_bw()
# Display the enhanced funnel plot
print(funnel_plot)
ggplot(aes(x = se, y = Zr), data = dat)+
# Add shaded areas for 95% and 99% CI regions
geom_ribbon(aes(x = se.seq, ymin = ll99, ymax = ul99), fill = "lightblue", alpha = 0.3)
dat
# Draw the enhanced funnel plot with shaded CI regions and lines
funnel_plot <- ggplot(aes(x = se, y = Zr), data = data)+
# Add shaded areas for 95% and 99% CI regions
geom_ribbon(aes(x = se.seq, ymin = ll99, ymax = ul99), fill = "lightblue", alpha = 0.3) +
geom_ribbon(aes(x = se.seq, ymin = ll95, ymax = ul95), fill = "lightgreen", alpha = 0.5) +
# Draw dashed lines for 95% and 99% CI bounds
geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', color = 'blue', data = dfCI) +
geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', color = 'blue', data = dfCI) +
geom_line(aes(x = se.seq, y = ll99), linetype = 'dashed', color = 'darkgreen', data = dfCI) +
geom_line(aes(x = se.seq, y = ul99), linetype = 'dashed', color = 'darkgreen', data = dfCI) +
# Add horizontal lines for mean 95% CI bounds
geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype = 'dotted', color = 'red', data = dfCI) +
geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype = 'dotted', color = 'red', data = dfCI) +
# Customize axis scaling and layout for clarity
scale_x_reverse() +
coord_flip() +
theme_bw()
# Display the enhanced funnel plot
print(funnel_plot)
# Draw the enhanced funnel plot with shaded CI regions and lines
funnel_plot <- ggplot(aes(x = var_smd, y = smd), data = data)+
# Add shaded areas for 95% and 99% CI regions
geom_ribbon(aes(x = se.seq, ymin = ll99, ymax = ul99), fill = "lightblue", alpha = 0.3) +
geom_ribbon(aes(x = se.seq, ymin = ll95, ymax = ul95), fill = "lightgreen", alpha = 0.5) +
# Draw dashed lines for 95% and 99% CI bounds
geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', color = 'blue', data = dfCI) +
geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', color = 'blue', data = dfCI) +
geom_line(aes(x = se.seq, y = ll99), linetype = 'dashed', color = 'darkgreen', data = dfCI) +
geom_line(aes(x = se.seq, y = ul99), linetype = 'dashed', color = 'darkgreen', data = dfCI) +
# Add horizontal lines for mean 95% CI bounds
geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype = 'dotted', color = 'red', data = dfCI) +
geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype = 'dotted', color = 'red', data = dfCI) +
# Customize axis scaling and layout for clarity
scale_x_reverse() +
coord_flip() +
theme_bw()
# Display the enhanced funnel plot
print(funnel_plot)
ggplot(aes(x = var_smd, y = smd), data = data)+
# Add shaded areas for 95% and 99% CI regions
geom_ribbon(aes(x = se.seq, ymin = ll99, ymax = ul99), fill = "lightblue", alpha = 0.3)
se.seq
ll99
ul99
# Store all calculated values in a single data frame for easy plotting
dfCI <- data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)
# Draw the enhanced funnel plot with shaded CI regions and lines
funnel_plot <- ggplot(aes(x = var_smd, y = smd), data = data)+
# Add shaded areas for 95% and 99% CI regions
geom_point(shape = 1) +
xlab('Standard Error') + ylab('Zr')+
geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +
geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +
geom_line(aes(x = se.seq, y = ll99), linetype = 'dashed', data = dfCI) +
geom_line(aes(x = se.seq, y = ul99), linetype = 'dashed', data = dfCI) +
geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +
geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +
scale_x_reverse()+
scale_y_continuous(breaks=seq(-1.25,2,0.25))+
coord_flip()+
theme_bw()
fp
# Display the enhanced funnel plot
funnel_plot
# Load the necessary library for meta-forest analysis
library(metaforest)
# Example dataset with effect sizes (yi), variances (vi), and potential moderators
dat <- data.frame(
yi = c(0.2, 0.3, 0.15, 0.4, 0.35, 0.1, 0.25),
vi = c(0.02, 0.03, 0.025, 0.04, 0.035, 0.01, 0.02),
mod1 = c("A", "B", "A", "B", "A", "B", "A"),  # Categorical moderator
mod2 = c(10, 20, 15, 25, 20, 10, 30)          # Continuous moderator
)
# Fit a meta-forest model
meta_forest_model <- MetaForest(yi ~ mod1 + mod2, vi = dat$vi, data = dat)
# Fit a meta-forest model
meta_forest_model <- MetaForest(yi ~ mod1 + mod2, vi = vi, data = dat)
data <- fukkink_lont
mf_rep <- MetaForest(yi~.,
data = data,
study = "id_exp",
whichweights = "random",
num.trees = 5000)
mf_rep <- MetaForest(yi~.,
data = dat,
study = "id_exp",
whichweights = "random",
num.trees = 5000)
fukkink_lont
names(fukkink_lont)
# Load required libraries
library(metaforest)
library(caret)
# Hypothetical dataset: Replace this with your own meta-analysis data
set.seed(123)
data_agro <- data.frame(
yi = rnorm(60, 0.3, 0.2),         # Simulated effect sizes
vi = rnorm(60, 0.1, 0.05),        # Variances of the effect sizes
Intervention = sample(c("Fruit", "Mixed", "Timber"), 60, replace = TRUE),
StudyID = rep(1:15, each = 4),    # 15 unique studies
Region = sample(c("Tropical", "Temperate"), 60, replace = TRUE)
)
# Step 1: Run initial MetaForest model with many trees to check convergence
initial_model <- MetaForest(
formula = yi ~ Intervention + Region,
data = data_agro,
study = "StudyID",
whichweights = "random",          # Use random-effects weighting scheme
num.trees = 15000                 # Set a high number of trees for convergence
)
data_agro$vi
data_agro <- data.frame(
yi = rnorm(60, 0.3, 0.2),         # Simulated effect sizes
vi = min(0.01,rnorm(60, 0.1, 0.05)),        # Variances of the effect sizes
Intervention = sample(c("Fruit", "Mixed", "Timber"), 60, replace = TRUE),
StudyID = rep(1:15, each = 4),    # 15 unique studies
Region = sample(c("Tropical", "Temperate"), 60, replace = TRUE)
)
# Step 1: Run initial MetaForest model with many trees to check convergence
initial_model <- MetaForest(
formula = yi ~ Intervention + Region,
data = data_agro,
study = "StudyID",
whichweights = "random",          # Use random-effects weighting scheme
num.trees = 15000                 # Set a high number of trees for convergence
)
# Step 2: Plot convergence trajectory (Mean Squared Error vs. Number of Trees)
plot(initial_model)
# Step 3: Tune MetaForest model using cross-validation with `caret`
# Define the parameter grid for tuning
tuning_grid <- expand.grid(
whichweights = c("random", "fixed", "unif"),
mtry = 2:4,                       # Number of variables to possibly split at in each node
min.node.size = 2:5               # Minimum size of terminal nodes
)
# Setup 10-fold cross-validation
grouped_cv <- trainControl(method = "cv", index = groupKFold(data_agro$StudyID, k = 10))
# Train MetaForest model using `caret` for optimal tuning
tuned_model <- train(
y = data_agro$yi,
x = data_agro[, c("Intervention", "Region", "StudyID", "vi")],
method = ModelInfo_mf(),           # MetaForest method setup for `caret`
trControl = grouped_cv,            # Cross-validation setup
tuneGrid = tuning_grid,            # Grid of tuning parameters
num.trees = 5000                   # Number of trees for final model
)
# Step 4: Examine the optimal tuning parameters and model performance
best_params <- tuned_model$results[which.min(tuned_model$results$RMSE), ]
# Step 3: Tune MetaForest model using cross-validation with `caret`
# Define the parameter grid for tuning
tuning_grid <- expand.grid(
whichweights = c("random", "fixed", "unif"),
mtry = 1:2,                       # Number of variables to possibly split at in each node
min.node.size = 2:5               # Minimum size of terminal nodes
)
# Setup 10-fold cross-validation
grouped_cv <- trainControl(method = "cv", index = groupKFold(data_agro$StudyID, k = 10))
# Train MetaForest model using `caret` for optimal tuning
tuned_model <- train(
y = data_agro$yi,
x = data_agro[, c("Intervention", "Region", "StudyID", "vi")],
method = ModelInfo_mf(),           # MetaForest method setup for `caret`
trControl = grouped_cv,            # Cross-validation setup
tuneGrid = tuning_grid,            # Grid of tuning parameters
num.trees = 5000                   # Number of trees for final model
)
# Step 4: Examine the optimal tuning parameters and model performance
best_params <- tuned_model$results[which.min(tuned_model$results$RMSE), ]
print(best_params)
# Step 5: Assess the final model and visualize results
final_model <- tuned_model$finalModel
# R² from out-of-bag predictions (OOB R² indicates model fit for unseen data)
r2_oob <- final_model$forest$r.squared
cat("OOB R-squared: ", r2_oob)
# Variable importance plot to identify influential moderators
VarImpPlot(final_model)
# Step 6: Visualize partial dependence of top moderators
PartialDependence(final_model, vars = names(final_model$forest$variable.importance)[1:2], rawdata = TRUE, pi = 0.95)
